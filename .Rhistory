####H20
TrainingH20= as.h2o(Data_Cleaned_Train)
splits <- h2o.splitFrame(TrainingH20, c(0.9),  seed=1234)
trainDNN  <- h2o.assign(splits[[1]], "train.hex") # 60%
validDNN   <- h2o.assign(splits[[2]], "valid.hex") # 60%
TrainingH202= as.h2o(Data_Cleaned_Test)
splits2 <- h2o.splitFrame(TrainingH202,  seed=0)
testDNN <- h2o.assign(splits2[[1]], "test.hex")  # 20%
response <- "Act.Pts"
predictors <- c( "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK" )
m1 <- h2o.deeplearning(
model_id="dl_model_first",
training_frame=trainDNN,
validation_frame=validDNN,   ## validation dataset: used for scoring and early stopping
x=predictors,
y=response,
nfold = 5,
#activation="Rectifier",  ## default
hidden=c(300,100),       ## default: 2 hidden layers with 200 neurons each
variable_importances=T,
epochs = 5,
categorical_encoding = "OneHotInternal"
)
#################################Predictions
RFPred = predict( rf,  Data_Cleaned_Test[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )]
,type = c("response") )
RFPred_PlusMinus = predict( rf_PlusMinus,  Data_Cleaned_Train_PlusMinusTest[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )]
,type = c("response") )
plusMinus = Data_Cleaned_Train_PlusMinusTest$`Act.Pts` - RFPred_PlusMinus
RFPLUSMINUS_M = ceil(min(plusMinus))
RFPLUSMINUS_P = ceil(max(plusMinus))
testSparseMatrix = sparse.model.matrix(
Data_Cleaned_Test$`Act.Pts` ~
(Data_Cleaned_Test$Rating + Data_Cleaned_Test$`Usg.Proj` + Data_Cleaned_Test$Pts_Sal
+ Data_Cleaned_Test$`Min.Proj` + Data_Cleaned_Test$Pro + Data_Cleaned_Test$Bargain
+ Data_Cleaned_Test$Own1 + Data_Cleaned_Test$PER + Data_Cleaned_Test$Pts + Data_Cleaned_Test$Usage +
Data_Cleaned_Test$Opp_Plus_Minus + Data_Cleaned_Test$PaceD + Data_Cleaned_Test$TS_Per + Data_Cleaned_Test$Fouls_36 +
Data_Cleaned_Test$Points_Touch + Data_Cleaned_Test$Touches + Data_Cleaned_Test$Rest + Data_Cleaned_Test$Pts +
Data_Cleaned_Test$`Opp.Pts` + Data_Cleaned_Test$delta + Data_Cleaned_Test$Spread + Data_Cleaned_Test$O_U +
Data_Cleaned_Test$Spread_per + Data_Cleaned_Test$Upside + Data_Cleaned_Test$Duds + Data_Cleaned_Test$Count +
Data_Cleaned_Test$YPlus_Minus + Data_Cleaned_Test$YDuds + Data_Cleaned_Test$YCount+
Data_Cleaned_Test$REB + Data_Cleaned_Test$STL + Data_Cleaned_Test$BLK
))
xgbO = xgboost(data = dtrain ,booster = "gblinear" , eta = 0.1 , max_depth=50, nthread = 4,
nrounds=2000,objective = "reg:linear" , verbose = 0 )
predict(xgbO,testSparseMatrix )
testSparseMatrix_PlusMinus = sparse.model.matrix(
Data_Cleaned_Train_PlusMinusTest$`Act.Pts` ~
(Data_Cleaned_Train_PlusMinusTest$Rating + Data_Cleaned_Train_PlusMinusTest$`Usg.Proj` + Data_Cleaned_Train_PlusMinusTest$Pts_Sal
+ Data_Cleaned_Train_PlusMinusTest$`Min.Proj` + Data_Cleaned_Train_PlusMinusTest$Pro + Data_Cleaned_Train_PlusMinusTest$Bargain
+ Data_Cleaned_Train_PlusMinusTest$Own1 + Data_Cleaned_Train_PlusMinusTest$PER + Data_Cleaned_Train_PlusMinusTest$Pts + Data_Cleaned_Train_PlusMinusTest$Usage +
Data_Cleaned_Train_PlusMinusTest$Opp_Plus_Minus + Data_Cleaned_Train_PlusMinusTest$PaceD + Data_Cleaned_Train_PlusMinusTest$TS_Per + Data_Cleaned_Train_PlusMinusTest$Fouls_36 +
Data_Cleaned_Train_PlusMinusTest$Points_Touch + Data_Cleaned_Train_PlusMinusTest$Touches + Data_Cleaned_Train_PlusMinusTest$Rest + Data_Cleaned_Train_PlusMinusTest$Pts +
Data_Cleaned_Train_PlusMinusTest$`Opp.Pts` + Data_Cleaned_Train_PlusMinusTest$delta + Data_Cleaned_Train_PlusMinusTest$Spread + Data_Cleaned_Train_PlusMinusTest$O_U +
Data_Cleaned_Train_PlusMinusTest$Spread_per + Data_Cleaned_Train_PlusMinusTest$Upside + Data_Cleaned_Train_PlusMinusTest$Duds + Data_Cleaned_Train_PlusMinusTest$Count +
Data_Cleaned_Train_PlusMinusTest$YPlus_Minus + Data_Cleaned_Train_PlusMinusTest$YDuds + Data_Cleaned_Train_PlusMinusTest$YCount+    Data_Cleaned_Train_PlusMinusTest$PTS +
Data_Cleaned_Train_PlusMinusTest$REB + Data_Cleaned_Train_PlusMinusTest$STL + Data_Cleaned_Train_PlusMinusTest$BLK
))
xgbO_PlusMinus = xgboost(data = dtrain_PlusMinus ,booster = "gblinear" , eta = 0.1 , max_depth=50, nthread = 4,
nrounds=2000,objective = "reg:linear" , verbose = 0 )
plusMinus =  Data_Cleaned_Train_PlusMinusTest$`Act.Pts` - predict(xgbO_PlusMinus,testSparseMatrix_PlusMinus )
xgbPLUSMINUS_M = ceil(min(plusMinus))
xgbPLUSMINUS_P = ceil(max(plusMinus))
##################################
Prediction2 =  as.data.frame(RFPred)
Prediction2["RFPer"] = as.data.frame(  Prediction2["RFPred"]*100/(Data_Cleaned_Test$`Salary`) )
Prediction2["RF_M"] =  as.data.frame(RFPLUSMINUS_M)
Prediction2["RF_P"] =  as.data.frame(RFPLUSMINUS_P)
Prediction2["Actual"] =  as.data.frame(Data_Cleaned_Test$`Act.Pts`)
Prediction2["Salary"] =  as.data.frame(Data_Cleaned_Test$`Salary`)
Prediction2["Name"] =  as.data.frame(Data_Cleaned_Test$Player)
Prediction2["HTeam"] =  as.data.frame(Data_Cleaned_Test$Team)
Prediction2["Opp"] = as.data.frame(Data_Cleaned_Test$Opp)
Prediction2["Pts"] =  as.data.frame(Data_Cleaned_Test$Pts)
Prediction2["Pos"] =  as.data.frame(Data_Cleaned_Test$Pos)
Prediction2["Xgb"] = as.data.frame(predict(xgbO, testSparseMatrix))
Prediction2["XgbPer"] = as.data.frame(  Prediction2["Xgb"]*100/(Data_Cleaned_Test$`Salary`) )
Prediction2["xgb_M"] =  as.data.frame(xgbPLUSMINUS_M)
Prediction2["xgb_P"] =  as.data.frame(xgbPLUSMINUS_P)
Prediction2["DNN"] = as.data.frame(h2o.predict(m1,newdata=testDNN))
Prediction2["DNNPer"] = as.data.frame(  Prediction2["DNN"]*100/(Data_Cleaned_Test$`Salary`) )
Results = rbind(Results, Prediction2)
}
h2o.init()
for (each in 1:length(playerNames)){
Data_Cleaned_Test = subset(Data_Cleaned, Data_Cleaned$Date == DateCheck
& Data_Cleaned$Player == as.character(playerNames[each]) )
Data_Cleaned_Train = subset(Data_Cleaned, Data_Cleaned$Date != DateCheck
& Data_Cleaned$Player == as.character(playerNames[each]) )
print (playerNames[each])
print (each)
### This ensures atleast 1 row of data exists for prediction
if (nrow(Data_Cleaned_Test) < 1 ){
next
}
#### If less than 15 rows then use that Teams's data
if (nrow(Data_Cleaned_Train) < 15){
Data_Cleaned_Train = subset(Data_Cleaned, Data_Cleaned$Date != DateCheck
& Data_Cleaned$Team
== as.character( unique ( subset(Data_Cleaned, Data_Cleaned$Player == as.character(playerNames[each]) )$Team ) )
)
}
if (nrow(Data_Cleaned_Train) < 15){
next
}
#### People to skip
if (playerNames[each] == "Kay Felder" & playerNames[each] == "Ian Mahinmi" & playerNames[each] == "Jodie Meeks"){
next
}
######### Construct Models
indices = sample(1:nrow(Data_Cleaned_Train), 7, replace = FALSE)
Data_Cleaned_Train_PlusMinusTrain = Data_Cleaned_Train[-indices, ]
Data_Cleaned_Train_PlusMinusTest = Data_Cleaned_Train[indices, ]
#########RF
rf = randomForest( Data_Cleaned_Train[,c( "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK" )],
y = Data_Cleaned_Train[,c("Act.Pts")], ntree=100
,type='regression')
rf_PlusMinus =  randomForest( Data_Cleaned_Train_PlusMinusTrain[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )],
y = Data_Cleaned_Train_PlusMinusTrain[,c("Act.Pts")], ntree=100
,type='regression')
####XGB
trainSparceMatrix = sparse.model.matrix( Data_Cleaned_Train$`Act.Pts` ~
(Data_Cleaned_Train$Rating + Data_Cleaned_Train$`Usg.Proj` + Data_Cleaned_Train$Pts_Sal
+ Data_Cleaned_Train$`Min.Proj` + Data_Cleaned_Train$Pro + Data_Cleaned_Train$Bargain
+ Data_Cleaned_Train$Own1 + Data_Cleaned_Train$PER + Data_Cleaned_Train$Pts + Data_Cleaned_Train$Usage +
Data_Cleaned_Train$Opp_Plus_Minus + Data_Cleaned_Train$PaceD + Data_Cleaned_Train$TS_Per + Data_Cleaned_Train$Fouls_36 +
Data_Cleaned_Train$Points_Touch + Data_Cleaned_Train$Touches + Data_Cleaned_Train$Rest + Data_Cleaned_Train$Pts +
Data_Cleaned_Train$`Opp.Pts` + Data_Cleaned_Train$delta + Data_Cleaned_Train$Spread + Data_Cleaned_Train$O_U +
Data_Cleaned_Train$Spread_per + Data_Cleaned_Train$Upside + Data_Cleaned_Train$Duds + Data_Cleaned_Train$Count +
Data_Cleaned_Train$YPlus_Minus + Data_Cleaned_Train$YDuds + Data_Cleaned_Train$YCount+    Data_Cleaned_Train$PTS +
Data_Cleaned_Train$REB + Data_Cleaned_Train$STL + Data_Cleaned_Train$BLK ))
Labels = Matrix(Data_Cleaned_Train$`Act.Pts`, sparse = TRUE)
dtrain <- xgb.DMatrix(data = trainSparceMatrix, label=Labels)
trainSparceMatrix_PlusMinus = sparse.model.matrix(     Data_Cleaned_Train_PlusMinusTrain$`Act.Pts` ~
(Data_Cleaned_Train_PlusMinusTrain$Rating + Data_Cleaned_Train_PlusMinusTrain$`Usg.Proj` + Data_Cleaned_Train_PlusMinusTrain$Pts_Sal
+ Data_Cleaned_Train_PlusMinusTrain$`Min.Proj` + Data_Cleaned_Train_PlusMinusTrain$Pro + Data_Cleaned_Train_PlusMinusTrain$Bargain
+ Data_Cleaned_Train_PlusMinusTrain$Own1 + Data_Cleaned_Train_PlusMinusTrain$PER + Data_Cleaned_Train_PlusMinusTrain$Pts + Data_Cleaned_Train_PlusMinusTrain$Usage +
Data_Cleaned_Train_PlusMinusTrain$Opp_Plus_Minus + Data_Cleaned_Train_PlusMinusTrain$PaceD + Data_Cleaned_Train_PlusMinusTrain$TS_Per + Data_Cleaned_Train_PlusMinusTrain$Fouls_36 +
Data_Cleaned_Train_PlusMinusTrain$Points_Touch + Data_Cleaned_Train_PlusMinusTrain$Touches + Data_Cleaned_Train_PlusMinusTrain$Rest + Data_Cleaned_Train_PlusMinusTrain$Pts +
Data_Cleaned_Train_PlusMinusTrain$`Opp.Pts` + Data_Cleaned_Train_PlusMinusTrain$delta + Data_Cleaned_Train_PlusMinusTrain$Spread + Data_Cleaned_Train_PlusMinusTrain$O_U +
Data_Cleaned_Train_PlusMinusTrain$Spread_per + Data_Cleaned_Train_PlusMinusTrain$Upside + Data_Cleaned_Train_PlusMinusTrain$Duds + Data_Cleaned_Train_PlusMinusTrain$Count +
Data_Cleaned_Train_PlusMinusTrain$YPlus_Minus + Data_Cleaned_Train_PlusMinusTrain$YDuds + Data_Cleaned_Train_PlusMinusTrain$YCount+    Data_Cleaned_Train_PlusMinusTrain$PTS +
Data_Cleaned_Train_PlusMinusTrain$REB + Data_Cleaned_Train_PlusMinusTrain$STL + Data_Cleaned_Train_PlusMinusTrain$BLK ))
Labels_PlusMinus = Matrix(Data_Cleaned_Train_PlusMinusTrain$`Act.Pts`, sparse = TRUE)
dtrain_PlusMinus <- xgb.DMatrix(data = trainSparceMatrix_PlusMinus, label=Labels_PlusMinus)
####H20
TrainingH20= as.h2o(Data_Cleaned_Train)
splits <- h2o.splitFrame(TrainingH20, c(0.9),  seed=1234)
trainDNN  <- h2o.assign(splits[[1]], "train.hex") # 60%
validDNN   <- h2o.assign(splits[[2]], "valid.hex") # 60%
TrainingH202= as.h2o(Data_Cleaned_Test)
splits2 <- h2o.splitFrame(TrainingH202,  seed=0)
testDNN <- h2o.assign(splits2[[1]], "test.hex")  # 20%
response <- "Act.Pts"
predictors <- c( "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK" )
m1 <- h2o.deeplearning(
model_id="dl_model_first",
training_frame=trainDNN,
validation_frame=validDNN,   ## validation dataset: used for scoring and early stopping
x=predictors,
y=response,
nfold = 5,
#activation="Rectifier",  ## default
hidden=c(300,100),       ## default: 2 hidden layers with 200 neurons each
variable_importances=T,
epochs = 5,
categorical_encoding = "OneHotInternal"
)
#################################Predictions
RFPred = predict( rf,  Data_Cleaned_Test[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )]
,type = c("response") )
RFPred_PlusMinus = predict( rf_PlusMinus,  Data_Cleaned_Train_PlusMinusTest[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )]
,type = c("response") )
plusMinus = Data_Cleaned_Train_PlusMinusTest$`Act.Pts` - RFPred_PlusMinus
RFPLUSMINUS_M = ceil(min(plusMinus))
RFPLUSMINUS_P = ceil(max(plusMinus))
testSparseMatrix = sparse.model.matrix(
Data_Cleaned_Test$`Act.Pts` ~
(Data_Cleaned_Test$Rating + Data_Cleaned_Test$`Usg.Proj` + Data_Cleaned_Test$Pts_Sal
+ Data_Cleaned_Test$`Min.Proj` + Data_Cleaned_Test$Pro + Data_Cleaned_Test$Bargain
+ Data_Cleaned_Test$Own1 + Data_Cleaned_Test$PER + Data_Cleaned_Test$Pts + Data_Cleaned_Test$Usage +
Data_Cleaned_Test$Opp_Plus_Minus + Data_Cleaned_Test$PaceD + Data_Cleaned_Test$TS_Per + Data_Cleaned_Test$Fouls_36 +
Data_Cleaned_Test$Points_Touch + Data_Cleaned_Test$Touches + Data_Cleaned_Test$Rest + Data_Cleaned_Test$Pts +
Data_Cleaned_Test$`Opp.Pts` + Data_Cleaned_Test$delta + Data_Cleaned_Test$Spread + Data_Cleaned_Test$O_U +
Data_Cleaned_Test$Spread_per + Data_Cleaned_Test$Upside + Data_Cleaned_Test$Duds + Data_Cleaned_Test$Count +
Data_Cleaned_Test$YPlus_Minus + Data_Cleaned_Test$YDuds + Data_Cleaned_Test$YCount+
Data_Cleaned_Test$REB + Data_Cleaned_Test$STL + Data_Cleaned_Test$BLK
))
xgbO = xgboost(data = dtrain ,booster = "gblinear" , eta = 0.1 , max_depth=50, nthread = 4,
nrounds=2000,objective = "reg:linear" , verbose = 0 )
predict(xgbO,testSparseMatrix )
testSparseMatrix_PlusMinus = sparse.model.matrix(
Data_Cleaned_Train_PlusMinusTest$`Act.Pts` ~
(Data_Cleaned_Train_PlusMinusTest$Rating + Data_Cleaned_Train_PlusMinusTest$`Usg.Proj` + Data_Cleaned_Train_PlusMinusTest$Pts_Sal
+ Data_Cleaned_Train_PlusMinusTest$`Min.Proj` + Data_Cleaned_Train_PlusMinusTest$Pro + Data_Cleaned_Train_PlusMinusTest$Bargain
+ Data_Cleaned_Train_PlusMinusTest$Own1 + Data_Cleaned_Train_PlusMinusTest$PER + Data_Cleaned_Train_PlusMinusTest$Pts + Data_Cleaned_Train_PlusMinusTest$Usage +
Data_Cleaned_Train_PlusMinusTest$Opp_Plus_Minus + Data_Cleaned_Train_PlusMinusTest$PaceD + Data_Cleaned_Train_PlusMinusTest$TS_Per + Data_Cleaned_Train_PlusMinusTest$Fouls_36 +
Data_Cleaned_Train_PlusMinusTest$Points_Touch + Data_Cleaned_Train_PlusMinusTest$Touches + Data_Cleaned_Train_PlusMinusTest$Rest + Data_Cleaned_Train_PlusMinusTest$Pts +
Data_Cleaned_Train_PlusMinusTest$`Opp.Pts` + Data_Cleaned_Train_PlusMinusTest$delta + Data_Cleaned_Train_PlusMinusTest$Spread + Data_Cleaned_Train_PlusMinusTest$O_U +
Data_Cleaned_Train_PlusMinusTest$Spread_per + Data_Cleaned_Train_PlusMinusTest$Upside + Data_Cleaned_Train_PlusMinusTest$Duds + Data_Cleaned_Train_PlusMinusTest$Count +
Data_Cleaned_Train_PlusMinusTest$YPlus_Minus + Data_Cleaned_Train_PlusMinusTest$YDuds + Data_Cleaned_Train_PlusMinusTest$YCount+    Data_Cleaned_Train_PlusMinusTest$PTS +
Data_Cleaned_Train_PlusMinusTest$REB + Data_Cleaned_Train_PlusMinusTest$STL + Data_Cleaned_Train_PlusMinusTest$BLK
))
xgbO_PlusMinus = xgboost(data = dtrain_PlusMinus ,booster = "gblinear" , eta = 0.1 , max_depth=50, nthread = 4,
nrounds=2000,objective = "reg:linear" , verbose = 0 )
plusMinus =  Data_Cleaned_Train_PlusMinusTest$`Act.Pts` - predict(xgbO_PlusMinus,testSparseMatrix_PlusMinus )
xgbPLUSMINUS_M = ceil(min(plusMinus))
xgbPLUSMINUS_P = ceil(max(plusMinus))
##################################
Prediction2 =  as.data.frame(RFPred)
Prediction2["RFPer"] = as.data.frame(  Prediction2["RFPred"]*100/(Data_Cleaned_Test$`Salary`) )
Prediction2["RF_M"] =  as.data.frame(RFPLUSMINUS_M)
Prediction2["RF_P"] =  as.data.frame(RFPLUSMINUS_P)
Prediction2["Actual"] =  as.data.frame(Data_Cleaned_Test$`Act.Pts`)
Prediction2["Salary"] =  as.data.frame(Data_Cleaned_Test$`Salary`)
Prediction2["Name"] =  as.data.frame(Data_Cleaned_Test$Player)
Prediction2["HTeam"] =  as.data.frame(Data_Cleaned_Test$Team)
Prediction2["Opp"] = as.data.frame(Data_Cleaned_Test$Opp)
Prediction2["Pts"] =  as.data.frame(Data_Cleaned_Test$Pts)
Prediction2["Pos"] =  as.data.frame(Data_Cleaned_Test$Pos)
Prediction2["Xgb"] = as.data.frame(predict(xgbO, testSparseMatrix))
Prediction2["XgbPer"] = as.data.frame(  Prediction2["Xgb"]*100/(Data_Cleaned_Test$`Salary`) )
Prediction2["xgb_M"] =  as.data.frame(xgbPLUSMINUS_M)
Prediction2["xgb_P"] =  as.data.frame(xgbPLUSMINUS_P)
Prediction2["DNN"] = as.data.frame(h2o.predict(m1,newdata=testDNN))
Prediction2["DNNPer"] = as.data.frame(  Prediction2["DNN"]*100/(Data_Cleaned_Test$`Salary`) )
Results = rbind(Results, Prediction2)
}
for (each in 30:length(playerNames)){
Data_Cleaned_Test = subset(Data_Cleaned, Data_Cleaned$Date == DateCheck
& Data_Cleaned$Player == as.character(playerNames[each]) )
Data_Cleaned_Train = subset(Data_Cleaned, Data_Cleaned$Date != DateCheck
& Data_Cleaned$Player == as.character(playerNames[each]) )
print (playerNames[each])
print (each)
### This ensures atleast 1 row of data exists for prediction
if (nrow(Data_Cleaned_Test) < 1 ){
next
}
#### If less than 15 rows then use that Teams's data
if (nrow(Data_Cleaned_Train) < 15){
Data_Cleaned_Train = subset(Data_Cleaned, Data_Cleaned$Date != DateCheck
& Data_Cleaned$Team
== as.character( unique ( subset(Data_Cleaned, Data_Cleaned$Player == as.character(playerNames[each]) )$Team ) )
)
}
if (nrow(Data_Cleaned_Train) < 15){
next
}
#### People to skip
if (playerNames[each] == "Kay Felder" & playerNames[each] == "Ian Mahinmi" & playerNames[each] == "Jodie Meeks"){
next
}
######### Construct Models
indices = sample(1:nrow(Data_Cleaned_Train), 7, replace = FALSE)
Data_Cleaned_Train_PlusMinusTrain = Data_Cleaned_Train[-indices, ]
Data_Cleaned_Train_PlusMinusTest = Data_Cleaned_Train[indices, ]
#########RF
rf = randomForest( Data_Cleaned_Train[,c( "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK" )],
y = Data_Cleaned_Train[,c("Act.Pts")], ntree=100
,type='regression')
rf_PlusMinus =  randomForest( Data_Cleaned_Train_PlusMinusTrain[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )],
y = Data_Cleaned_Train_PlusMinusTrain[,c("Act.Pts")], ntree=100
,type='regression')
####XGB
trainSparceMatrix = sparse.model.matrix( Data_Cleaned_Train$`Act.Pts` ~
(Data_Cleaned_Train$Rating + Data_Cleaned_Train$`Usg.Proj` + Data_Cleaned_Train$Pts_Sal
+ Data_Cleaned_Train$`Min.Proj` + Data_Cleaned_Train$Pro + Data_Cleaned_Train$Bargain
+ Data_Cleaned_Train$Own1 + Data_Cleaned_Train$PER + Data_Cleaned_Train$Pts + Data_Cleaned_Train$Usage +
Data_Cleaned_Train$Opp_Plus_Minus + Data_Cleaned_Train$PaceD + Data_Cleaned_Train$TS_Per + Data_Cleaned_Train$Fouls_36 +
Data_Cleaned_Train$Points_Touch + Data_Cleaned_Train$Touches + Data_Cleaned_Train$Rest + Data_Cleaned_Train$Pts +
Data_Cleaned_Train$`Opp.Pts` + Data_Cleaned_Train$delta + Data_Cleaned_Train$Spread + Data_Cleaned_Train$O_U +
Data_Cleaned_Train$Spread_per + Data_Cleaned_Train$Upside + Data_Cleaned_Train$Duds + Data_Cleaned_Train$Count +
Data_Cleaned_Train$YPlus_Minus + Data_Cleaned_Train$YDuds + Data_Cleaned_Train$YCount+    Data_Cleaned_Train$PTS +
Data_Cleaned_Train$REB + Data_Cleaned_Train$STL + Data_Cleaned_Train$BLK ))
Labels = Matrix(Data_Cleaned_Train$`Act.Pts`, sparse = TRUE)
dtrain <- xgb.DMatrix(data = trainSparceMatrix, label=Labels)
trainSparceMatrix_PlusMinus = sparse.model.matrix(     Data_Cleaned_Train_PlusMinusTrain$`Act.Pts` ~
(Data_Cleaned_Train_PlusMinusTrain$Rating + Data_Cleaned_Train_PlusMinusTrain$`Usg.Proj` + Data_Cleaned_Train_PlusMinusTrain$Pts_Sal
+ Data_Cleaned_Train_PlusMinusTrain$`Min.Proj` + Data_Cleaned_Train_PlusMinusTrain$Pro + Data_Cleaned_Train_PlusMinusTrain$Bargain
+ Data_Cleaned_Train_PlusMinusTrain$Own1 + Data_Cleaned_Train_PlusMinusTrain$PER + Data_Cleaned_Train_PlusMinusTrain$Pts + Data_Cleaned_Train_PlusMinusTrain$Usage +
Data_Cleaned_Train_PlusMinusTrain$Opp_Plus_Minus + Data_Cleaned_Train_PlusMinusTrain$PaceD + Data_Cleaned_Train_PlusMinusTrain$TS_Per + Data_Cleaned_Train_PlusMinusTrain$Fouls_36 +
Data_Cleaned_Train_PlusMinusTrain$Points_Touch + Data_Cleaned_Train_PlusMinusTrain$Touches + Data_Cleaned_Train_PlusMinusTrain$Rest + Data_Cleaned_Train_PlusMinusTrain$Pts +
Data_Cleaned_Train_PlusMinusTrain$`Opp.Pts` + Data_Cleaned_Train_PlusMinusTrain$delta + Data_Cleaned_Train_PlusMinusTrain$Spread + Data_Cleaned_Train_PlusMinusTrain$O_U +
Data_Cleaned_Train_PlusMinusTrain$Spread_per + Data_Cleaned_Train_PlusMinusTrain$Upside + Data_Cleaned_Train_PlusMinusTrain$Duds + Data_Cleaned_Train_PlusMinusTrain$Count +
Data_Cleaned_Train_PlusMinusTrain$YPlus_Minus + Data_Cleaned_Train_PlusMinusTrain$YDuds + Data_Cleaned_Train_PlusMinusTrain$YCount+    Data_Cleaned_Train_PlusMinusTrain$PTS +
Data_Cleaned_Train_PlusMinusTrain$REB + Data_Cleaned_Train_PlusMinusTrain$STL + Data_Cleaned_Train_PlusMinusTrain$BLK ))
Labels_PlusMinus = Matrix(Data_Cleaned_Train_PlusMinusTrain$`Act.Pts`, sparse = TRUE)
dtrain_PlusMinus <- xgb.DMatrix(data = trainSparceMatrix_PlusMinus, label=Labels_PlusMinus)
####H20
TrainingH20= as.h2o(Data_Cleaned_Train)
splits <- h2o.splitFrame(TrainingH20, c(0.9),  seed=1234)
trainDNN  <- h2o.assign(splits[[1]], "train.hex") # 60%
validDNN   <- h2o.assign(splits[[2]], "valid.hex") # 60%
TrainingH202= as.h2o(Data_Cleaned_Test)
splits2 <- h2o.splitFrame(TrainingH202,  seed=0)
testDNN <- h2o.assign(splits2[[1]], "test.hex")  # 20%
response <- "Act.Pts"
predictors <- c( "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK" )
m1 <- h2o.deeplearning(
model_id="dl_model_first",
training_frame=trainDNN,
validation_frame=validDNN,   ## validation dataset: used for scoring and early stopping
x=predictors,
y=response,
nfold = 5,
#activation="Rectifier",  ## default
hidden=c(300,100),       ## default: 2 hidden layers with 200 neurons each
variable_importances=T,
epochs = 5,
categorical_encoding = "OneHotInternal"
)
#################################Predictions
RFPred = predict( rf,  Data_Cleaned_Test[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )]
,type = c("response") )
RFPred_PlusMinus = predict( rf_PlusMinus,  Data_Cleaned_Train_PlusMinusTest[,c(  "Rating","Salary","Proj","Ceiling","Floor","Proj_Plus_Minus","Pts_Sal","Usg.Proj","Min.Proj",
"Own1","Own2","Imp.Pts","FP_Min","PER",
"Usage","Pro","Bargain","Opp_Plus_Minus","PaceD","TS_Per","Fouls_36",
"Points_Touch","Touches","Rest","Pts","Opp.Pts","delta","Spread",
"O_U","Spread_per","PPG","Consistency",
"Upside","Duds","Count","YPPG","YPlus_Minus","YConsistency","YUpside","YDuds","YCount","PTS","REB","STL","BLK"  )]
,type = c("response") )
plusMinus = Data_Cleaned_Train_PlusMinusTest$`Act.Pts` - RFPred_PlusMinus
RFPLUSMINUS_M = ceil(min(plusMinus))
RFPLUSMINUS_P = ceil(max(plusMinus))
testSparseMatrix = sparse.model.matrix(
Data_Cleaned_Test$`Act.Pts` ~
(Data_Cleaned_Test$Rating + Data_Cleaned_Test$`Usg.Proj` + Data_Cleaned_Test$Pts_Sal
+ Data_Cleaned_Test$`Min.Proj` + Data_Cleaned_Test$Pro + Data_Cleaned_Test$Bargain
+ Data_Cleaned_Test$Own1 + Data_Cleaned_Test$PER + Data_Cleaned_Test$Pts + Data_Cleaned_Test$Usage +
Data_Cleaned_Test$Opp_Plus_Minus + Data_Cleaned_Test$PaceD + Data_Cleaned_Test$TS_Per + Data_Cleaned_Test$Fouls_36 +
Data_Cleaned_Test$Points_Touch + Data_Cleaned_Test$Touches + Data_Cleaned_Test$Rest + Data_Cleaned_Test$Pts +
Data_Cleaned_Test$`Opp.Pts` + Data_Cleaned_Test$delta + Data_Cleaned_Test$Spread + Data_Cleaned_Test$O_U +
Data_Cleaned_Test$Spread_per + Data_Cleaned_Test$Upside + Data_Cleaned_Test$Duds + Data_Cleaned_Test$Count +
Data_Cleaned_Test$YPlus_Minus + Data_Cleaned_Test$YDuds + Data_Cleaned_Test$YCount+
Data_Cleaned_Test$REB + Data_Cleaned_Test$STL + Data_Cleaned_Test$BLK
))
xgbO = xgboost(data = dtrain ,booster = "gblinear" , eta = 0.1 , max_depth=50, nthread = 4,
nrounds=2000,objective = "reg:linear" , verbose = 0 )
predict(xgbO,testSparseMatrix )
testSparseMatrix_PlusMinus = sparse.model.matrix(
Data_Cleaned_Train_PlusMinusTest$`Act.Pts` ~
(Data_Cleaned_Train_PlusMinusTest$Rating + Data_Cleaned_Train_PlusMinusTest$`Usg.Proj` + Data_Cleaned_Train_PlusMinusTest$Pts_Sal
+ Data_Cleaned_Train_PlusMinusTest$`Min.Proj` + Data_Cleaned_Train_PlusMinusTest$Pro + Data_Cleaned_Train_PlusMinusTest$Bargain
+ Data_Cleaned_Train_PlusMinusTest$Own1 + Data_Cleaned_Train_PlusMinusTest$PER + Data_Cleaned_Train_PlusMinusTest$Pts + Data_Cleaned_Train_PlusMinusTest$Usage +
Data_Cleaned_Train_PlusMinusTest$Opp_Plus_Minus + Data_Cleaned_Train_PlusMinusTest$PaceD + Data_Cleaned_Train_PlusMinusTest$TS_Per + Data_Cleaned_Train_PlusMinusTest$Fouls_36 +
Data_Cleaned_Train_PlusMinusTest$Points_Touch + Data_Cleaned_Train_PlusMinusTest$Touches + Data_Cleaned_Train_PlusMinusTest$Rest + Data_Cleaned_Train_PlusMinusTest$Pts +
Data_Cleaned_Train_PlusMinusTest$`Opp.Pts` + Data_Cleaned_Train_PlusMinusTest$delta + Data_Cleaned_Train_PlusMinusTest$Spread + Data_Cleaned_Train_PlusMinusTest$O_U +
Data_Cleaned_Train_PlusMinusTest$Spread_per + Data_Cleaned_Train_PlusMinusTest$Upside + Data_Cleaned_Train_PlusMinusTest$Duds + Data_Cleaned_Train_PlusMinusTest$Count +
Data_Cleaned_Train_PlusMinusTest$YPlus_Minus + Data_Cleaned_Train_PlusMinusTest$YDuds + Data_Cleaned_Train_PlusMinusTest$YCount+    Data_Cleaned_Train_PlusMinusTest$PTS +
Data_Cleaned_Train_PlusMinusTest$REB + Data_Cleaned_Train_PlusMinusTest$STL + Data_Cleaned_Train_PlusMinusTest$BLK
))
xgbO_PlusMinus = xgboost(data = dtrain_PlusMinus ,booster = "gblinear" , eta = 0.1 , max_depth=50, nthread = 4,
nrounds=2000,objective = "reg:linear" , verbose = 0 )
plusMinus =  Data_Cleaned_Train_PlusMinusTest$`Act.Pts` - predict(xgbO_PlusMinus,testSparseMatrix_PlusMinus )
xgbPLUSMINUS_M = ceil(min(plusMinus))
xgbPLUSMINUS_P = ceil(max(plusMinus))
##################################
Prediction2 =  as.data.frame(RFPred)
Prediction2["RFPer"] = as.data.frame(  Prediction2["RFPred"]*100/(Data_Cleaned_Test$`Salary`) )
Prediction2["RF_M"] =  as.data.frame(RFPLUSMINUS_M)
Prediction2["RF_P"] =  as.data.frame(RFPLUSMINUS_P)
Prediction2["Actual"] =  as.data.frame(Data_Cleaned_Test$`Act.Pts`)
Prediction2["Salary"] =  as.data.frame(Data_Cleaned_Test$`Salary`)
Prediction2["Name"] =  as.data.frame(Data_Cleaned_Test$Player)
Prediction2["HTeam"] =  as.data.frame(Data_Cleaned_Test$Team)
Prediction2["Opp"] = as.data.frame(Data_Cleaned_Test$Opp)
Prediction2["Pts"] =  as.data.frame(Data_Cleaned_Test$Pts)
Prediction2["Pos"] =  as.data.frame(Data_Cleaned_Test$Pos)
Prediction2["Xgb"] = as.data.frame(predict(xgbO, testSparseMatrix))
Prediction2["XgbPer"] = as.data.frame(  Prediction2["Xgb"]*100/(Data_Cleaned_Test$`Salary`) )
Prediction2["xgb_M"] =  as.data.frame(xgbPLUSMINUS_M)
Prediction2["xgb_P"] =  as.data.frame(xgbPLUSMINUS_P)
Prediction2["DNN"] = as.data.frame(h2o.predict(m1,newdata=testDNN))
Prediction2["DNNPer"] = as.data.frame(  Prediction2["DNN"]*100/(Data_Cleaned_Test$`Salary`) )
Results = rbind(Results, Prediction2)
}
Results
Backup = Results
Results[,"ActualPos"] = 0
Results[,"Rank"] = 0
Results[,"L5"] = 0
Results[,"L10"] = 0
Results[,"Player_Per"] = 0
Results[,"Player_Med"] = 0
Results[,"Player_Projected"] = 0
colnames(Position) = c("Pos","PName")
Dvoa = read.csv("DVOA_Rank.csv", header = FALSE)
colnames(Dvoa) = c("TeamName","TNShort","Pos","L5","L10","PTS","REB","AST","STL","BLK","3PM","FGP",
"FTP","TO","Rank")
for(each in 1:nrow(Results)){
# Find actual Position
P = subset(Position, Position$PName == as.character(Results[each,"Name"]) )
if (nrow(P) > 0){
Results[each, "ActualPos"] = as.character(P[1,"Pos"])
}
#Find Rank, L5, L10
P = subset(Dvoa, Dvoa$TNShort == as.character(Results[each,"Opp"]) &
Dvoa$Pos == as.character(Results[each,"ActualPos"])  )
if (nrow(P) > 0){
Results[each, "Rank"] = as.numeric(P$Rank)
Results[each, "L5"] = as.numeric(P$L5)
Results[each, "L10"] = as.numeric(P$L10)
}
}
All_17$Act.Pts = as.numeric(All_17$Act.Pts)
for(each in 1:nrow(Results)){
######### Split ###
### if Postition was not found then use Position from FL
if ( Results[each, "ActualPos"] == "0"){
positions = ((unlist(strsplit(as.character( Results[each, "Pos"] ), "/"))))
if (length(positions) > 1 ){
sub_T = subset(All_17, All_17$Team == as.character(Results[each, "HTeam"]) )
T1 =  subset( sub_T , grepl(positions[1], sub_T$Pos))
T2 =  subset( sub_T , grepl(positions[2], sub_T$Pos))
T1 = rbind(T1,T2)
T1 = unique(T1)
}
if (length(positions) == 1){
sub_T = subset(All_17, All_17$Team == as.character(Results[each, "HTeam"]) )
T1 =  subset( sub_T , grepl(positions[1], sub_T$Pos))
T1 = unique(T1)
}
}
### if ActualPos is providied as they are starters then you don't need to use FL probable positions
if (Results[each, "ActualPos"] != "0") {
positions = Results[each, "ActualPos"]
sub_T = subset(All_17, All_17$Team == as.character(Results[each, "HTeam"]) )
T1 =  subset( sub_T , grepl(positions[1], sub_T$Pos))
T1 = unique(T1)
}
### Get All players in that position on this team
Player_Points = subset(T1, T1$Player == as.character(Results[each, "Name"])  )
NonPlayer_Points = subset(T1, T1$Player != as.character(Results[each, "Name"]))
### Remove  Starters who have flexible position
if (Results[each, "ActualPos"] != "0"){
playes_NotFound = unique(NonPlayer_Points$Player)
for(each2 in 1:length(playes_NotFound)){
C =  which(Results$Name == as.character(playes_NotFound[each2]) )
if ( length(C) > 0 ) {
if (Results[C,"ActualPos"] != "0" ){
NonPlayer_Points = subset(NonPlayer_Points, NonPlayer_Points$Player != as.character(Results[C, "Name"]))
}
}
}
}
Results[each,"Player_Per"] = sum((Player_Points$`Act.Pts`)) / ( sum((Player_Points$`Act.Pts`)) + sum((NonPlayer_Points$`Act.Pts`)) )
Results[each,"Player_Med"] = median(Player_Points$`Act.Pts`)
Results[each,"Player_Projected"] =  Results[each, "L5"] * Results[each,"Player_Per"]
}
Results = unique(Results)
write.csv(Results, file = "NBA_Test_v01_25_2018.csv")
